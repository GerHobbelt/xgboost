% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xgb.importance.R
\name{xgb.importance}
\alias{xgb.importance}
\title{Show importance of features in a model}
\usage{
xgb.importance(feature_names, filename_dump)
}
\arguments{
\item{feature_names}{names of each feature as a \code{character} vector. Can be extracted from a sparse matrix (see example). If model dump already contains feature names, this argument should be \code{NULL}.}

\item{filename_dump}{character. Filename of the xgboost dump generated by the \code{xgb.dump} function.}
}
\value{
A \code{list} of the features used in the model with their relative importance in the model.
}
\description{
Create a \code{list} of the most important features of a model.
}
\details{
This implementation of variable importance algorithm is agnostic of the type of tree that is built.
For each variable, we calculate the number of splits that are made on this variable and assign is as the
importance value for the aforementioned variable. This turns out to be a pretty good proxy for
how influential a variable's change are on the resulting model score.
}

